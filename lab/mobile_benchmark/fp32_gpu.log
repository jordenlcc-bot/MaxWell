INFO: STARTING!
INFO: Log parameter values verbosely: [0]
INFO: Min num runs: [100]
INFO: Min warmup runs: [10]
INFO: Graph: [/data/local/tmp/mobilenet_v2_fp32.tflite]
INFO: Signature to run: []
INFO: Use gpu: [1]
INFO: Loaded model /data/local/tmp/mobilenet_v2_fp32.tflite
INFO: Initialized TensorFlow Lite runtime.
INFO: GPU delegate created.
INFO: Created TensorFlow Lite delegate for GPU.
INFO: Loaded OpenCL library with dlopen.
VERBOSE: Replacing 65 out of 65 node(s) with delegate (TfLiteGpuDelegateV2) node, yielding 1 partitions for subgraph 0.
Could not open module param file '/sys/module/mali_kbase/parameters/large_page_conf'
INFO: Initialized OpenCL-based API.
INFO: Created 1 GPU delegate kernels.
INFO: Explicitly applied GPU delegate, and the model graph will be completely executed by the delegate.
INFO: The input model file size (MB): 13.9849
INFO: Initialized session in 1295.83ms.
INFO: Running benchmark for at least 10 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
INFO: count=22 first=26072 curr=22896 min=21286 max=26072 avg=22400.7 std=937 p5=21344 median=22295 p95=23235

INFO: Running benchmark for at least 100 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
INFO: count=100 first=23731 curr=24644 min=18833 max=26139 avg=24077.3 std=1074 p5=22067 median=24248 p95=25037

INFO: Inference timings in us: Init: 1295830, First inference: 26072, Warmup (avg): 22400.7, Inference (avg): 24077.3
INFO: Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
INFO: Memory footprint delta from the start of the tool (MB): init=125.164 overall=125.164
